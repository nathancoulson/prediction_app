{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from random import randint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "from math import sin\n",
    "from math import pi\n",
    "from math import exp\n",
    "from random import randint\n",
    "from random import uniform\n",
    "\n",
    "from numpy import array\n",
    "from math import ceil\n",
    "from math import log10\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import RepeatVector\n",
    "\n",
    "from random import random\n",
    "from numpy import cumsum\n",
    "from numpy import array_equal\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "pd.set_option('display.max_columns', 999)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = pd.read_parquet(\"logs.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature transformations\n",
    "\n",
    "# Convert resp_time and bytes_setn into float\n",
    "\n",
    "log_df.resp_time = log_df.resp_time.astype(\"float\")\n",
    "log_df.bytes_sent = log_df.bytes_sent.astype(\"float\")\n",
    "\n",
    "# Convert datetime string into Pandas Datetime\n",
    "\n",
    "log_df.datetime = pd.to_datetime(log_df.datetime,\n",
    "                                    format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# Create categorical variables\n",
    "\n",
    "log_df = pd.get_dummies(log_df, columns = ['resp_code'])\n",
    "log_df = pd.get_dummies(log_df, columns = ['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create url request only dataframe\n",
    "\n",
    "log_df.columns.tolist()\n",
    "\n",
    "url_features = [col for col in log_df.columns if \"url\" in col]\n",
    "\n",
    "req_df = log_df[url_features]\n",
    "\n",
    "req_df.shape\n",
    "\n",
    "# Create subset (every 10th request) and trim\n",
    "\n",
    "small_req_df = req_df.iloc[::2, :]\n",
    "\n",
    "small_req_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequence prediction outcome variable -> next 250 requests\n",
    "\n",
    "for url in url_features:\n",
    "     small_req_df[\"CS_\" + url] = small_req_df[url].rolling(250).sum()\n",
    "\n",
    "cumsum_cols = [col for col in small_req_df.columns if \"CS_\" in col]\n",
    "        \n",
    "# Delete NaN rows\n",
    "\n",
    "small_req_df.dropna(inplace=True)\n",
    "\n",
    "# Shift output variable 250 places down\n",
    "\n",
    "small_req_df[cumsum_cols] = small_req_df[cumsum_cols].shift(-250)\n",
    "\n",
    "# Delete NaN rows again\n",
    "\n",
    "small_req_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_req_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim to size\n",
    "\n",
    "small_req_df = small_req_df.iloc[0:2241000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X and y\n",
    "\n",
    "y = array(small_req_df[cumsum_cols]).reshape(2241000,129)\n",
    "\n",
    "\n",
    "X = small_req_df[[col for col in small_req_df.columns if \"CS_\" not in col]].to_numpy()\n",
    "X = X.reshape(2241,1000,129)\n",
    "\n",
    "# Get the thousandth request vector for y\n",
    "\n",
    "sub_y = y[::1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(1000, 129)))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(129))\n",
    "model.compile(loss='cosine_proximity', optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "# fit model\n",
    "history = model.fit(X, sub_y, batch_size=32, epochs=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "# evaluate model\n",
    "X, y = generate_examples(length, 1000, output)\n",
    "loss = model.evaluate(X, y, verbose=0)\n",
    "print('MAE: %f' % loss)\n",
    "\n",
    "# prediction on new data\n",
    "X, y = generate_examples(length, 1, output)\n",
    "yhat = model.predict(X, verbose=0)\n",
    "pyplot.plot(y[0], label='y')\n",
    "pyplot.plot(yhat[0], label='yhat')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X[2100].reshape(1,1000,129)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[2100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".micro",
   "language": "python",
   "name": ".micro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
